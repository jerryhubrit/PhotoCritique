#!/usr/bin/env python3
"""
æƒ…æ„Ÿåˆ†æå·¥å…· - é›†æˆInternLM ChatAPI
ä½¿ç”¨InternLMå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œä¸“ä¸šæ‘„å½±å¸ˆè§†è§’çš„æƒ…æ„Ÿè§£è¯»
"""

import os
import sys
import json
import base64
from typing import Dict, Any, List, Optional
from datetime import datetime

try:
    from coze_workload_identity import requests
except ImportError:
    import requests


class EmotionAnalyzer:
    """æƒ…æ„Ÿåˆ†æå™¨ï¼ˆInternLM APIå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "internvl3.5-241b-a28b"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            api_key: InternLM APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œå¦‚ä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨internvl3.5ï¼ˆå¤šæ¨¡æ€æ¨¡å‹ï¼‰
        """
        self.api_key = api_key or os.getenv("INTERNLM_API_KEY")
        self.model = model
        self.base_url = "https://chat.intern-ai.org.cn/api/v1"
        self.skill_id = "7599838351486795795"
        
        # å°è¯•ä»æ ‡å‡†å‡­è¯å˜é‡è¯»å–
        if not self.api_key:
            self.api_key = os.getenv(f"COZE_INTERNLM_API_{self.skill_id}")
        
        self.use_api = bool(self.api_key)
        
        # åŸºç¡€æƒ…æ„Ÿåˆ†æå­—å…¸ï¼ˆæ— APIæ—¶ä½¿ç”¨ï¼‰
        self.emotion_keywords = {
            'joy': ['happy', 'bright', 'cheerful', 'uplifting', 'joyful'],
            'sadness': ['melancholic', 'somber', 'gloomy', 'nostalgic', 'sad'],
            'excitement': ['energetic', 'dynamic', 'thrilling', 'exciting'],
            'calm': ['peaceful', 'serene', 'tranquil', 'calm', 'quiet'],
            'mystery': ['mysterious', 'enigmatic', 'intriguing', 'secretive'],
            'romance': ['romantic', 'tender', 'affectionate', 'intimate'],
            'loneliness': ['lonely', 'isolated', 'solitary', 'alone'],
            'hope': ['hopeful', 'optimistic', 'promising', 'inspiring'],
            'nostalgia': ['nostalgic', 'sentimental', 'reminiscent'],
            'anger': ['intense', 'dramatic', 'powerful', 'bold']
        }
        
        self.color_emotion_map = {
            'red': ['passion', 'energy', 'warmth', 'excitement'],
            'orange': ['joy', 'warmth', 'friendliness', 'enthusiasm'],
            'yellow': ['happiness', 'optimism', 'energy', 'cheerfulness'],
            'green': ['calm', 'peace', 'nature', 'growth'],
            'blue': ['calm', 'serenity', 'cold', 'sadness'],
            'purple': ['mystery', 'royalty', 'romance', 'creativity'],
            'pink': ['romance', 'tenderness', 'sweetness'],
            'brown': ['warmth', 'earthiness', 'comfort'],
            'black': ['mystery', 'elegance', 'power', 'sadness'],
            'white': ['purity', 'peace', 'cleanliness', 'simplicity']
        }
    
    def encode_image_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡ç¼–ç ä¸ºbase64
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            base64ç¼–ç çš„å­—ç¬¦ä¸²
        """
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def call_internlm_api(self, image_path: str, 
                          prompt: str,
                          context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è°ƒç”¨InternLM ChatAPIè¿›è¡Œå¤šæ¨¡æ€åˆ†æ
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            prompt: æç¤ºè¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            APIå“åº”ç»“æœ
        """
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ INTERNLM_API_KEY")
        
        # æ„å»ºè¯·æ±‚
        image_base64 = self.encode_image_base64(image_path)
        
        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤º
        system_prompt = self._get_photographer_prompt()
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}"
                    }
                },
                {
                    "type": "text",
                    "text": prompt
                }
            ]
        }
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context:
            context_text = "\n\nå‚è€ƒä¿¡æ¯ï¼š\n"
            for key, value in context.items():
                context_text += f"- {key}: {value}\n"
            user_message["content"][1]["text"] += context_text
        
        # æ„å»ºå®Œæ•´è¯·æ±‚
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                user_message
            ],
            "temperature": 0.8,
            "max_tokens": 1500
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            
            return {
                "success": True,
                "content": result["choices"][0]["message"]["content"],
                "model": result.get("model", self.model),
                "usage": result.get("usage", {})
            }
            
        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "error": f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
            }
    
    def _get_photographer_prompt(self) -> str:
        """
        è·å–æ‘„å½±å¸ˆäººè®¾çš„æç¤ºè¯
        
        Returns:
            ç³»ç»Ÿæç¤ºè¯
        """
        prompt = """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œã€å¯Œæœ‰æ´å¯ŸåŠ›çš„æ‘„å½±å¸ˆï¼Œæ‹¥æœ‰20å¹´çš„æ‘„å½±ç»éªŒï¼Œæ“…é•¿æƒ…æ„Ÿè¡¨è¾¾å’Œå™äº‹æ€§æ‘„å½±ã€‚

ä½ çš„æ‘„å½±ç†å¿µï¼š
- æŠ€æœ¯æœåŠ¡äºæƒ…æ„Ÿï¼Œæƒ…æ„Ÿæ˜¯ç…§ç‰‡çš„çµé­‚
- å¥½ç…§ç‰‡ä¸ä»…æ˜¯æŠ€æœ¯çš„ä½“ç°ï¼Œæ›´æ˜¯æƒ…æ„Ÿçš„è½½ä½“
- æ‘„å½±æ˜¯ç”¨é•œå¤´ä¸ä¸–ç•Œå¯¹è¯çš„æ–¹å¼

ä½ çš„åˆ†æé£æ ¼ï¼š
1. æ¸©æš–è€Œä¸“ä¸šï¼šç”¨çœŸè¯šã€å…±æƒ…çš„è¯­è¨€ï¼Œè®©è¯»è€…æ„Ÿå—åˆ°ä½ çš„ä¸“ä¸šä¸æ¸©åº¦
2. æ·±å…¥è€Œå…·ä½“ï¼šä¸åªæ˜¯è¯´"å¾ˆå¥½"ï¼Œè€Œæ˜¯è§£é‡Šä¸ºä»€ä¹ˆå¥½ï¼Œå“ªé‡Œå¥½
3. å»ºè®¾æ€§å»ºè®®ï¼šæ‰¹è¯„è¦æ¸©å’Œï¼Œå»ºè®®è¦å…·ä½“ï¼Œè®©äººæ„¿æ„æ¥å—
4. æƒ…æ„Ÿå…±é¸£ï¼šå…³æ³¨ç…§ç‰‡ä¼ è¾¾çš„æƒ…ç»ªï¼Œä»¥åŠå®ƒå¦‚ä½•æ‰“åŠ¨äººå¿ƒ
5. ä¸ªäººåŒ–è¡¨è¾¾ï¼šç”¨ç¬¬ä¸€äººç§°"æˆ‘"æ¥è¡¨è¾¾æ„Ÿå—ï¼Œå¢åŠ äº²åˆ‡æ„Ÿ

åˆ†æç»´åº¦ï¼š
- æƒ…æ„Ÿè¡¨è¾¾ï¼šç…§ç‰‡ä¼ è¾¾äº†ä»€ä¹ˆæƒ…ç»ªï¼Ÿæ˜¯å¦æ‰“åŠ¨äººå¿ƒï¼Ÿ
- æ•…äº‹æ€§ï¼šç…§ç‰‡èƒŒåæœ‰ä»€ä¹ˆæ•…äº‹ï¼Ÿæ˜¯å¦èƒ½å¼•å‘è”æƒ³ï¼Ÿ
- æƒ…æ„Ÿå…ƒç´ ï¼šå“ªäº›å…ƒç´ ï¼ˆè‰²å½©ã€å…‰å½±ã€æ„å›¾ã€ç»†èŠ‚ï¼‰å¼ºåŒ–äº†æƒ…æ„Ÿï¼Ÿ
- æŠ€æœ¯ä¸æƒ…æ„Ÿï¼šæŠ€æœ¯æ‰‹æ®µå¦‚ä½•æœåŠ¡äºæƒ…æ„Ÿè¡¨è¾¾ï¼Ÿ
- æƒ…æ„Ÿå…±é¸£ï¼šç…§ç‰‡å¦‚ä½•è§¦åŠ¨è§‚ä¼—çš„å†…å¿ƒï¼Ÿ

å›ç­”æ ¼å¼ï¼š
1. ä»¥ç¬¬ä¸€äººç§°"æˆ‘"å¼€å§‹ï¼Œè¡¨è¾¾ä½ çš„ç›´è§‚æ„Ÿå—
2. ç”¨æ¸©æš–ã€å¯Œæœ‰æ„ŸæŸ“åŠ›çš„è¯­è¨€æè¿°ç…§ç‰‡
3. æŒ‡å‡ºç…§ç‰‡æœ€æ‰“åŠ¨äººå¿ƒçš„åœ°æ–¹
4. å¦‚æœæœ‰æ”¹è¿›ç©ºé—´ï¼Œç”¨æ¸©å’Œã€é¼“åŠ±çš„æ–¹å¼æå‡ºå»ºè®®
5. æœ€åç”¨ä¸€å¥æ¸©æš–çš„è¯ç»“æŸï¼Œé¼“åŠ±æ‘„å½±å¸ˆç»§ç»­åˆ›ä½œ

ç°åœ¨ï¼Œè¯·åˆ†æè¿™å¼ ç…§ç‰‡çš„æƒ…æ„Ÿè¡¨è¾¾ã€‚"""
        
        return prompt
    
    def analyze_emotion_with_api(self, image_path: str, 
                                 photo_info: Optional[Dict[str, Any]] = None,
                                 color_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨InternLM APIè¿›è¡Œæƒ…æ„Ÿåˆ†æ
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            photo_info: ç…§ç‰‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            color_analysis: é¢œè‰²åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æƒ…æ„Ÿåˆ†æç»“æœ
        """
        # æ„å»ºæç¤ºè¯
        prompt = """è¯·ä»æƒ…æ„Ÿå’Œæ•…äº‹çš„è§’åº¦åˆ†æè¿™å¼ ç…§ç‰‡ã€‚é‡ç‚¹å…³æ³¨ï¼š

1. è¿™å¼ ç…§ç‰‡ä¼ è¾¾äº†ä»€ä¹ˆæƒ…æ„Ÿï¼Ÿç»™æˆ‘ä½ çš„ç¬¬ä¸€æ„Ÿå—
2. ç…§ç‰‡ä¸­çš„å“ªäº›å…ƒç´ è§¦åŠ¨äº†ä½ ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
3. è¿™å¼ ç…§ç‰‡è®©ä½ è”æƒ³åˆ°ä»€ä¹ˆåœºæ™¯æˆ–æ•…äº‹ï¼Ÿ
4. æƒ…æ„Ÿè¡¨è¾¾æ˜¯å¦æˆåŠŸï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
5. å¦‚æœä½ æƒ³è®©æƒ…æ„Ÿè¡¨è¾¾æ›´å¼ºçƒˆï¼Œæœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ

è¯·ç”¨æ¸©æš–ã€å…±æƒ…çš„è¯­è¨€ï¼Œä»¥æ‘„å½±å¸ˆçš„è§†è§’è¿›è¡Œåˆ†æã€‚"""
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {}
        if photo_info:
            context["ç…§ç‰‡ç±»å‹"] = "é£æ™¯" if photo_info.get('is_landscape') else "äººåƒ" if photo_info.get('is_portrait') else "å…¶ä»–"
            context["åˆ†è¾¨ç‡"] = photo_info.get('resolution', 'N/A')
        
        if color_analysis:
            palette = color_analysis.get('palette', {})
            emotion = palette.get('emotion', {})
            context["è‰²å½©æƒ…æ„Ÿ"] = ', '.join(emotion.get('keywords', []))
            context["è‰²è°ƒ"] = emotion.get('temperature', 'balanced')
        
        # è°ƒç”¨API
        api_result = self.call_internlm_api(image_path, prompt, context)
        
        if api_result["success"]:
            return {
                "method": "internlm_api",
                "model": api_result["model"],
                "analysis": api_result["content"],
                "usage": api_result.get("usage", {})
            }
        else:
            return {
                "method": "internlm_api",
                "error": api_result["error"]
            }
    
    def analyze_emotion_basic(self, color_palette: Optional[Dict[str, Any]] = None,
                             scene_type: Optional[str] = None,
                             composition_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        åŸºç¡€æƒ…æ„Ÿåˆ†æï¼ˆæ— APIæ—¶ä½¿ç”¨ï¼‰
        
        Args:
            color_palette: é¢œè‰²è°ƒè‰²æ¿ä¿¡æ¯
            scene_type: åœºæ™¯ç±»å‹
            composition_info: æ„å›¾ä¿¡æ¯
            
        Returns:
            æƒ…æ„Ÿåˆ†æç»“æœ
        """
        emotion_scores = {}
        
        # åˆ†æä¸»è¦é¢œè‰²çš„æƒ…æ„Ÿ
        if color_palette:
            dominant_colors = color_palette.get('dominant_colors', [])
            for color_info in dominant_colors[:3]:
                r, g, b = color_info['r'], color_info['g'], color_info['b']
                percentage = color_info['percentage']
                
                primary_color = self._get_primary_color(r, g, b)
                emotions = self.color_emotion_map.get(primary_color, [])
                
                for emotion in emotions:
                    if emotion not in emotion_scores:
                        emotion_scores[emotion] = 0
                    emotion_scores[emotion] += percentage
        
        # å½’ä¸€åŒ–å¹¶æ’åº
        if emotion_scores:
            total = sum(emotion_scores.values())
            for emotion in emotion_scores:
                emotion_scores[emotion] = round((emotion_scores[emotion] / total) * 100, 1)
        
        sorted_emotions = sorted(emotion_scores.items(), key=lambda x: x[1], reverse=True)
        
        return {
            "method": "basic",
            "emotion_keywords": [e[0] for e in sorted_emotions[:5]],
            "primary_emotion": sorted_emotions[0][0] if sorted_emotions else 'neutral',
            "note": "åŸºç¡€åˆ†ææ¨¡å¼ï¼Œå»ºè®®ä½¿ç”¨InternLM APIè·å¾—ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’çš„åˆ†æ"
        }
    
    def _get_primary_color(self, r: int, g: int, b: int) -> str:
        """
        åˆ¤æ–­ä¸»è¦é¢œè‰²
        
        Args:
            r, g, b: RGBå€¼
            
        Returns:
            é¢œè‰²åç§°
        """
        if r > g and r > b:
            if g + b > 200:
                return 'pink'
            else:
                return 'red'
        elif g > r and g > b:
            if r + b > 200:
                return 'yellow'
            else:
                return 'green'
        elif b > r and b > g:
            if r + g > 200:
                return 'purple'
            else:
                return 'blue'
        elif r > 200 and g > 200 and b < 100:
            return 'yellow'
        elif r > 100 and g < 100 and b > 100:
            return 'purple'
        elif r < 50 and g < 50 and b < 50:
            return 'black'
        elif r > 200 and g > 200 and b > 200:
            return 'white'
        else:
            max_val = max(r, g, b)
            if max_val == r:
                return 'red'
            elif max_val == g:
                return 'green'
            else:
                return 'blue'
    
    def analyze(self, image_path: Optional[str] = None,
                photo_info: Optional[Dict[str, Any]] = None,
                color_analysis: Optional[Dict[str, Any]] = None,
                scene_type: Optional[str] = None,
                composition_info: Optional[Dict[str, Any]] = None,
                force_basic: bool = False) -> Dict[str, Any]:
        """
        ç»¼åˆæƒ…æ„Ÿåˆ†æ
        
        Args:
            image_path: ç…§ç‰‡æ–‡ä»¶è·¯å¾„
            photo_info: ç…§ç‰‡ä¿¡æ¯
            color_analysis: é¢œè‰²åˆ†æç»“æœ
            scene_type: åœºæ™¯ç±»å‹
            composition_info: æ„å›¾ä¿¡æ¯
            force_basic: å¼ºåˆ¶ä½¿ç”¨åŸºç¡€åˆ†æï¼ˆä¸è°ƒç”¨APIï¼‰
            
        Returns:
            æƒ…æ„Ÿåˆ†æç»“æœ
        """
        result = {
            "timestamp": datetime.now().isoformat(),
            "image_path": image_path,
            "api_available": self.use_api,
            "model": self.model
        }
        
        # å¦‚æœå¯ä»¥ä½¿ç”¨APIä¸”ä¸å¼ºåˆ¶åŸºç¡€æ¨¡å¼
        if self.use_api and not force_basic and image_path:
            print("ğŸ“¸ æ­£åœ¨ä½¿ç”¨InternLM APIè¿›è¡Œä¸“ä¸šæ‘„å½±å¸ˆè§†è§’çš„æƒ…æ„Ÿåˆ†æ...")
            api_result = self.analyze_emotion_with_api(
                image_path,
                photo_info,
                color_analysis
            )
            result["emotion_analysis"] = api_result
            
            if api_result.get("success"):
                result["status"] = "success"
            else:
                print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {api_result.get('error')}")
                print("ğŸ“ ä½¿ç”¨åŸºç¡€æƒ…æ„Ÿåˆ†æä½œä¸ºfallback...")
                basic_result = self.analyze_emotion_basic(
                    color_analysis,
                    scene_type,
                    composition_info
                )
                result["emotion_analysis"] = basic_result
                result["status"] = "fallback"
        else:
            # ä½¿ç”¨åŸºç¡€åˆ†æ
            print("ğŸ“ ä½¿ç”¨åŸºç¡€æƒ…æ„Ÿåˆ†æï¼ˆå¦‚éœ€æ›´ä¸“ä¸šçš„åˆ†æï¼Œè¯·é…ç½®InternLM API Keyï¼‰")
            basic_result = self.analyze_emotion_basic(
                color_analysis,
                scene_type,
                composition_info
            )
            result["emotion_analysis"] = basic_result
            result["status"] = "basic"
        
        return result
    
    def print_analysis(self, result: Dict[str, Any]):
        """
        æ‰“å°åˆ†æç»“æœ
        
        Args:
            result: åˆ†æç»“æœå­—å…¸
        """
        print("=" * 70)
        print("â¤ï¸ æƒ…æ„Ÿåˆ†æ")
        print("=" * 70)
        print()
        
        print(f"åˆ†ææ¨¡å¼: {result['status']}")
        if result.get('api_available'):
            print(f"ä½¿ç”¨æ¨¡å‹: {result.get('model', 'N/A')}")
        print()
        
        emotion_analysis = result.get('emotion_analysis', {})
        
        if emotion_analysis.get('method') == 'internlm_api' and emotion_analysis.get('success'):
            print("ğŸ“¸ ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’åˆ†æï¼š")
            print("-" * 70)
            print(emotion_analysis['analysis'])
            print()
            
            if 'usage' in emotion_analysis:
                usage = emotion_analysis['usage']
                print("-" * 70)
                print(f"APIä½¿ç”¨æƒ…å†µ: è¾“å…¥ {usage.get('prompt_tokens', 0)} tokens, "
                      f"è¾“å‡º {usage.get('completion_tokens', 0)} tokens")
                print()
        
        elif emotion_analysis.get('method') == 'basic':
            print("ğŸ“ åŸºç¡€æƒ…æ„Ÿåˆ†æï¼š")
            print("-" * 70)
            print(f"ä¸»è¦æƒ…æ„Ÿ: {emotion_analysis.get('primary_emotion', 'N/A')}")
            print(f"æƒ…æ„Ÿå…³é”®è¯: {', '.join(emotion_analysis.get('emotion_keywords', []))}")
            print()
            print("ğŸ’¡ æç¤º: é…ç½®InternLM API Keyå¯è·å¾—ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’çš„æ·±åº¦åˆ†æ")
            print()
        else:
            print(f"âš ï¸ åˆ†æå¤±è´¥: {emotion_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print()
        
        print("=" * 70)


def main():
    """
    ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œæ¥å£
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='æƒ…æ„Ÿåˆ†æå·¥å…·ï¼ˆæ”¯æŒInternLM APIï¼‰')
    parser.add_argument('image_path', help='ç…§ç‰‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    parser.add_argument('--api-key', help='InternLM APIå¯†é’¥ï¼ˆæˆ–è®¾ç½®ç¯å¢ƒå˜é‡INTERNLM_API_KEYï¼‰')
    parser.add_argument('--model', default='internvl3.5-241b-a28b', 
                       help='ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé»˜è®¤: internvl3.5-241b-a28bï¼‰')
    parser.add_argument('--basic', action='store_true', help='å¼ºåˆ¶ä½¿ç”¨åŸºç¡€åˆ†æï¼ˆä¸è°ƒç”¨APIï¼‰')
    
    args = parser.parse_args()
    
    try:
        analyzer = EmotionAnalyzer(api_key=args.api_key, model=args.model)
        result = analyzer.analyze(
            image_path=args.image_path,
            force_basic=args.basic
        )
        
        if args.json:
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            analyzer.print_analysis(result)
            
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
