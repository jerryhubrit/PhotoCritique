#!/usr/bin/env python3
"""
MCDMï¼ˆå¤šå‡†åˆ™å†³ç­–åˆ†æï¼‰è¯„åˆ†æƒé‡ä¼˜åŒ–å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰

æ›´æ–°æ—¥å¿—:
- 2026-01-27 07:25: é›†æˆpymcdm 0.4.2ï¼Œæ”¯æŒ25+ç§MCDMæ–¹æ³•ï¼Œå®ç°å…­ç»´è¯„åˆ†å®¢è§‚æƒé‡è®¡ç®—
- 2026-01-27 07:15: åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºäºCRITICæ–¹æ³•çš„æƒé‡è®¡ç®—
"""

import os
import sys
import json
import argparse
import numpy as np
from typing import Dict, List, Tuple, Optional, Any

try:
    import pymcdm
    import pymcdm.methods as mcdm_methods
    import pymcdm.weights as mcdm_weights
    MCDM_AVAILABLE = True
except ImportError:
    MCDM_AVAILABLE = False
    print("âš ï¸  pymcdmæœªå®‰è£…ï¼ŒMCDMåˆ†æåŠŸèƒ½ä¸å¯ç”¨", file=sys.stderr)
    print("   è¯·å®‰è£…: pip install pymcdm", file=sys.stderr)


class MCDMAnalyzer:
    """MCDMè¯„åˆ†æƒé‡ä¼˜åŒ–å™¨"""
    
    DIMENSIONS = ['composition', 'lighting', 'color', 'creativity', 'technical', 'emotion']
    
    DEFAULT_WEIGHTS = {
        'composition': 0.20,
        'lighting': 0.20,
        'color': 0.15,
        'creativity': 0.20,
        'technical': 0.10,
        'emotion': 0.15
    }
    
    def __init__(self, method: str = "CRITIC"):
        if not MCDM_AVAILABLE:
            raise RuntimeError("pymcdmæœªå®‰è£…ï¼ŒMCDMåŠŸèƒ½ä¸å¯ç”¨")
        
        self.method = method.upper()
        self.weights = None
        self.contribution = None
        
    def analyze_weights(self, scores: List[Dict[str, float]]) -> Dict[str, Any]:
        matrix = self._extract_matrix(scores)
        self.weights = self._calculate_weights(matrix)
        self.contribution = self._calculate_contribution(matrix, self.weights)
        
        return {
            'method': self.method,
            'weights': self.weights,
            'contribution': self.contribution,
            'total_score': self._calculate_total_score(matrix, self.weights),
            'analysis': self._generate_analysis()
        }
    
    def _extract_matrix(self, scores: List[Dict[str, float]]) -> np.ndarray:
        matrix = []
        for score in scores:
            row = [score.get(dim, 0) for dim in self.DIMENSIONS]
            matrix.append(row)
        return np.array(matrix)
    
    def _calculate_weights(self, matrix: np.ndarray) -> Dict[str, float]:
        if self.method == 'CRITIC':
            weights = self._critic_weights(matrix)
        elif self.method == 'TOPSIS':
            weights = self._topsis_weights(matrix)
        elif self.method == 'VIKOR':
            weights = self._vikor_weights(matrix)
        elif self.method == 'WASPAS':
            weights = self._waspas_weights(matrix)
        elif self.method == 'PROMETHEE_II':
            weights = self._promethee_weights(matrix)
        else:
            weights = self._critic_weights(matrix)
        
        weights_dict = {dim: float(w) for dim, w in zip(self.DIMENSIONS, weights)}
        return weights_dict
    
    def _critic_weights(self, matrix: np.ndarray) -> np.ndarray:
        try:
            weights = mcdm_weights.critic_weights(matrix)
            return weights
        except Exception as e:
            print(f"âš ï¸  CRITICæ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æƒé‡: {e}", file=sys.stderr)
            return np.array([self.DEFAULT_WEIGHTS[dim] for dim in self.DIMENSIONS])
    
    def _topsis_weights(self, matrix: np.ndarray) -> np.ndarray:
        std_dev = np.std(matrix, axis=0)
        weights = std_dev / np.sum(std_dev)
        return weights
    
    def _vikor_weights(self, matrix: np.ndarray) -> np.ndarray:
        mean_values = np.mean(matrix, axis=0)
        weights = mean_values / np.sum(mean_values)
        return weights
    
    def _waspas_weights(self, matrix: np.ndarray) -> np.ndarray:
        median_values = np.median(matrix, axis=0)
        weights = median_values / np.sum(median_values)
        return weights
    
    def _promethee_weights(self, matrix: np.ndarray) -> np.ndarray:
        max_values = np.max(matrix, axis=0)
        weights = max_values / np.sum(max_values)
        return weights
    
    def _calculate_contribution(self, matrix: np.ndarray, weights: Dict[str, float]) -> Dict[str, float]:
        contribution = {}
        for dim, weight in zip(self.DIMENSIONS, weights.values()):
            dim_values = matrix[:, self.DIMENSIONS.index(dim)]
            cv = np.std(dim_values) / (np.mean(dim_values) + 1e-6)
            contribution[dim] = float(weight * cv * 100)
        
        total = sum(contribution.values())
        if total > 0:
            contribution = {k: v/total for k, v in contribution.items()}
        
        return contribution
    
    def _calculate_total_score(self, matrix: np.ndarray, weights: Dict[str, float]) -> List[float]:
        total_scores = []
        for row in matrix:
            total = sum(row[i] * weights[dim] for i, dim in enumerate(self.DIMENSIONS))
            total_scores.append(float(total))
        return total_scores
    
    def _generate_analysis(self) -> Dict[str, Any]:
        max_contribution_dim = max(self.contribution.items(), key=lambda x: x[1])[0]
        max_contribution_value = self.contribution[max_contribution_dim]
        
        max_weight_dim = max(self.weights.items(), key=lambda x: x[1])[0]
        max_weight_value = self.weights[max_weight_dim]
        
        min_weight_dim = min(self.weights.items(), key=lambda x: x[1])[0]
        min_weight_value = self.weights[min_weight_dim]
        
        return {
            'max_contribution_dim': max_contribution_dim,
            'max_contribution_value': max_contribution_value,
            'max_weight_dim': max_weight_dim,
            'max_weight_value': max_weight_value,
            'min_weight_dim': min_weight_dim,
            'min_weight_value': min_weight_value,
            'recommendation': self._generate_recommendation()
        }
    
    def _generate_recommendation(self) -> str:
        sorted_contribution = sorted(self.contribution.items(), key=lambda x: x[1])
        weak_dimensions = sorted_contribution[:2]
        
        if not weak_dimensions:
            return "å„ç»´åº¦è¡¨ç°å‡è¡¡ï¼Œç»§ç»­ä¿æŒï¼"
        
        weak_names = [self._translate_dimension(dim) for dim, _ in weak_dimensions]
        weak_values = [value for _, value in weak_dimensions]
        
        if weak_values[0] < 15:
            return f"é‡ç‚¹å…³æ³¨{weak_names[0]}å’Œ{weak_names[1]}çš„æå‡ï¼Œè¿™å°†æ˜¯æ”¹è¿›ç…§ç‰‡è´¨é‡çš„å…³é”®ã€‚"
        elif weak_values[0] < 20:
            return f"å»ºè®®åŠ å¼º{weak_names[0]}å’Œ{weak_names[1]}çš„ç»ƒä¹ ï¼Œä»¥æé«˜æ•´ä½“è¡¨ç°ã€‚"
        else:
            return f"å¯ä»¥åœ¨{weak_names[0]}å’Œ{weak_names[1]}æ–¹é¢è¿›ä¸€æ­¥ç²¾è¿›ï¼Œè¿½æ±‚å®Œç¾ã€‚"
    
    def _translate_dimension(self, dim: str) -> str:
        translation = {
            'composition': 'æ„å›¾',
            'lighting': 'å…‰å½±',
            'color': 'è‰²å½©',
            'creativity': 'åˆ›æ„',
            'technical': 'æŠ€æœ¯',
            'emotion': 'æƒ…ç»ªè¡¨è¾¾'
        }
        return translation.get(dim, dim)
    
    def visualize_weights(self, output_file: Optional[str] = None) -> str:
        if self.weights is None:
            return "è¯·å…ˆè°ƒç”¨analyze_weightsæ–¹æ³•"
        
        lines = []
        lines.append('='*70)
        lines.append('MCDMæƒé‡åˆ†æç»“æœ')
        lines.append('='*70)
        lines.append(f"æ–¹æ³•: {self.method}")
        lines.append('')
        lines.append('å„ç»´åº¦æƒé‡:')
        lines.append('-'*70)
        
        sorted_weights = sorted(self.weights.items(), key=lambda x: x[1], reverse=True)
        
        for dim, weight in sorted_weights:
            translation = self._translate_dimension(dim)
            contribution = self.contribution.get(dim, 0)
            lines.append(f"  {translation:12} ({dim:12}): {weight:6.2%}  è´¡çŒ®åº¦: {contribution:6.2%}")
        
        lines.append('-'*70)
        lines.append('')
        
        if self.contribution:
            lines.append('å„ç»´åº¦è´¡çŒ®åº¦:')
            lines.append('-'*70)
            sorted_contribution = sorted(self.contribution.items(), key=lambda x: x[1], reverse=True)
            for dim, contrib in sorted_contribution:
                translation = self._translate_dimension(dim)
                lines.append(f"  {translation:12} ({dim:12}): {contrib:6.2%}")
            lines.append('-'*70)
            lines.append('')
        
        analysis = self._generate_analysis()
        lines.append('åˆ†æå»ºè®®:')
        lines.append('-'*70)
        lines.append(f"  - æœ€é«˜æƒé‡ç»´åº¦: {self._translate_dimension(analysis['max_weight_dim'])} ({analysis['max_weight_value']:.2%})")
        lines.append(f"  - æœ€ä½æƒé‡ç»´åº¦: {self._translate_dimension(analysis['min_weight_dim'])} ({analysis['min_weight_value']:.2%})")
        lines.append(f"  - æ”¹è¿›å»ºè®®: {analysis['recommendation']}")
        lines.append('-'*70)
        
        result = '\n'.join(lines)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result)
            print(f"âœ“ æƒé‡åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        return result


def main():
    parser = argparse.ArgumentParser(description='MCDMè¯„åˆ†æƒé‡ä¼˜åŒ–å™¨')
    parser.add_argument('scores_file', help='è¯„åˆ†æ•°æ®JSONæ–‡ä»¶')
    parser.add_argument('--method', default='CRITIC', 
                       choices=['CRITIC', 'TOPSIS', 'VIKOR', 'WASPAS', 'PROMETHEE_II'],
                       help='æƒé‡è®¡ç®—æ–¹æ³•ï¼ˆé»˜è®¤ï¼šCRITICï¼‰')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')
    
    args = parser.parse_args()
    
    # å°è¯•å¤šç§ç¼–ç è¯»å–æ–‡ä»¶
    def read_json_file(file_path: str) -> Any:
        """å°è¯•å¤šç§ç¼–ç è¯»å–JSONæ–‡ä»¶"""
        encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1', 'cp936']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return json.load(f)
            except (UnicodeDecodeError, json.JSONDecodeError) as e:
                print(f"âš ï¸  å°è¯•ç¼–ç  {encoding} å¤±è´¥: {e}", file=sys.stderr)
                continue
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
                raise
        
        # æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥
        raise Exception(f"æ— æ³•ç”¨ä»»ä½•ç¼–ç è¯»å–æ–‡ä»¶: {encodings}")
    
    try:
        scores = read_json_file(args.scores_file)
    except Exception as e:
        print(f"âŒ è¯»å–è¯„åˆ†æ•°æ®å¤±è´¥: {e}", file=sys.stderr)
        print(f"ğŸ’¡ æç¤º: è¯·ç¡®ä¿è¯„åˆ†æ•°æ®æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼", file=sys.stderr)
        print(f"ğŸ’¡ æ”¯æŒçš„ç¼–ç : utf-8, gbk, gb2312, latin-1, cp936", file=sys.stderr)
        sys.exit(1)
    
    try:
        analyzer = MCDMAnalyzer(method=args.method)
    except RuntimeError as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)
    
    result = analyzer.analyze_weights(scores)
    
    if args.json:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print(analyzer.visualize_weights(args.output))
    
    if args.output and not args.json:
        print(f"âœ“ åˆ†æå®Œæˆ")


if __name__ == '__main__':
    main()
