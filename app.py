#!/usr/bin/env python3
"""
æ™ºèƒ½æ‘„å½±å­¦ä¹ åŠ©æ‰‹ - Web ç•Œé¢
æ”¯æŒå¤šå›¾ä¸Šä¼ ã€æ‰¹é‡åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import json
import gradio as gr
from datetime import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path

# æ·»åŠ è„šæœ¬è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'photo-tutor/scripts'))

from photo_analyzer import extract_basic_info
from color_analyzer import ColorAestheticsAnalyzer
from emotion_analyzer import EmotionAnalyzer


class PhotoTutorApp:
    """æ™ºèƒ½æ‘„å½±å­¦ä¹ åŠ©æ‰‹åº”ç”¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        # åŠ è½½ç¯å¢ƒå˜é‡
        self._load_env()
        
        # åˆå§‹åŒ–åˆ†æå™¨
        self.color_analyzer = ColorAestheticsAnalyzer()
        self.emotion_analyzer = EmotionAnalyzer()
        
    def _load_env(self):
        """åŠ è½½ .env æ–‡ä»¶"""
        env_path = Path(__file__).parent / '.env'
        if env_path.exists():
            with open(env_path) as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
    
    def analyze_single_photo(self, image_path: str) -> Dict[str, Any]:
        """
        åˆ†æå•å¼ ç…§ç‰‡
        
        Args:
            image_path: ç…§ç‰‡è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        result = {
            "image_path": image_path,
            "image_name": os.path.basename(image_path),
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # 1. åŸºç¡€ä¿¡æ¯æå–
            basic_info = extract_basic_info(image_path)
            result["basic_info"] = basic_info
            
            # 2. è‰²å½©ç¾å­¦åˆ†æ
            color_analysis = self.color_analyzer.analyze(image_path)
            result["color_analysis"] = color_analysis
            
            # 3. æƒ…æ„Ÿåˆ†æ
            emotion_result = self.emotion_analyzer.analyze(
                image_path=image_path,
                photo_info=basic_info,
                color_analysis=color_analysis
            )
            result["emotion_analysis"] = emotion_result
            
            result["status"] = "success"
            
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
        
        return result
    
    def format_basic_info(self, info: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åŸºç¡€ä¿¡æ¯"""
        lines = []
        lines.append("### ğŸ“¸ åŸºç¡€ä¿¡æ¯")
        lines.append(f"- **æ–‡ä»¶å**: {info.get('file_name', 'N/A')}")
        lines.append(f"- **åˆ†è¾¨ç‡**: {info.get('resolution', 'N/A')}")
        lines.append(f"- **é•¿å®½æ¯”**: {info.get('aspect_ratio', 'N/A')} ({'ç«–æ‹' if info.get('is_portrait') else 'æ¨ªæ‹' if info.get('is_landscape') else 'æ–¹å½¢'})")
        lines.append(f"- **å¹³å‡äº®åº¦**: {info.get('mean_brightness', 'N/A')} ({info.get('brightness_level', 'N/A')})")
        lines.append(f"- **å¯¹æ¯”åº¦**: {info.get('contrast', 'N/A')} ({info.get('contrast_level', 'N/A')})")
        
        # EXIFä¿¡æ¯
        if 'aperture' in info or 'shutter_speed' in info or 'iso' in info:
            lines.append("\n**æ‹æ‘„å‚æ•°**:")
            if 'aperture' in info:
                lines.append(f"- å…‰åœˆ: {info['aperture']}")
            if 'shutter_speed' in info:
                lines.append(f"- å¿«é—¨: {info['shutter_speed']}")
            if 'iso' in info:
                lines.append(f"- ISO: {info['iso']}")
            if 'focal_length' in info:
                lines.append(f"- ç„¦è·: {info['focal_length']}")
        
        return "\n".join(lines)
    
    def format_color_analysis(self, analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è‰²å½©åˆ†æ"""
        lines = []
        lines.append("### ğŸ¨ è‰²å½©ç¾å­¦åˆ†æ")
        
        # ä¸»è¦è‰²å½©
        palette = analysis.get('palette', {})
        dominant_colors = palette.get('dominant_colors', [])
        if dominant_colors:
            lines.append("\n**ä¸»è¦è‰²å½©**:")
            for i, color in enumerate(dominant_colors[:5], 1):
                hex_code = color.get('hex', 'N/A')
                name = color.get('name', 'unknown')
                percentage = color.get('percentage', 0)
                lines.append(f"{i}. <span style='color:{hex_code};font-weight:bold;'>â—</span> {hex_code} ({name}) - {percentage}%")
        
        # å’Œè°åº¦
        harmony = analysis.get('harmony', {})
        if harmony:
            lines.append(f"\n**è‰²å½©å’Œè°åº¦**: {harmony.get('score', 'N/A')}/100")
            lines.append(f"- ç±»å‹: {harmony.get('type', 'N/A')}")
            lines.append(f"- æè¿°: {harmony.get('description', 'N/A')}")
        
        # è‰²å½©å¿ƒç†å­¦
        emotion = palette.get('emotion', {})
        if emotion:
            lines.append(f"\n**è‰²å½©å¿ƒç†å­¦**:")
            lines.append(f"- ä¸»å¯¼æƒ…æ„Ÿ: {', '.join(emotion.get('keywords', []))}")
            lines.append(f"- è‰²æ¸©: {emotion.get('temperature', 'N/A')}")
            lines.append(f"- å¼ºåº¦: {emotion.get('intensity', 'N/A')}")
            lines.append(f"- å¿ƒç†å­¦è¯„åˆ†: {emotion.get('score', 'N/A')}/100")
        
        # ç»¼åˆè¯„åˆ†
        lines.append(f"\n**ç¾å­¦ç»¼åˆè¯„åˆ†**: {analysis.get('overall_score', 'N/A')}/100")
        
        return "\n".join(lines)
    
    def format_emotion_analysis(self, analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æƒ…æ„Ÿåˆ†æ"""
        lines = []
        lines.append("### â¤ï¸ æƒ…æ„Ÿåˆ†æ")
        
        emotion_data = analysis.get('emotion_analysis', {})
        status = analysis.get('status', 'unknown')
        
        lines.append(f"\n**åˆ†ææ¨¡å¼**: {status}")
        lines.append(f"**ä½¿ç”¨æ¨¡å‹**: {analysis.get('model', 'N/A')}")
        
        if emotion_data.get('method') == 'internlm_api' and emotion_data.get('success'):
            lines.append("\n**ğŸ“¸ ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’åˆ†æ**:")
            lines.append("---")
            lines.append(emotion_data.get('analysis', ''))
            
            usage = emotion_data.get('usage', {})
            if usage:
                lines.append("\n---")
                lines.append(f"*APIä½¿ç”¨: è¾“å…¥ {usage.get('prompt_tokens', 0)} tokens, è¾“å‡º {usage.get('completion_tokens', 0)} tokens*")
        else:
            # åŸºç¡€åˆ†æ
            lines.append("\n**åŸºç¡€æƒ…æ„Ÿåˆ†æ**:")
            lines.append(f"- ä¸»è¦æƒ…æ„Ÿ: {emotion_data.get('primary_emotion', 'neutral')}")
            keywords = emotion_data.get('emotion_keywords', [])
            if keywords:
                lines.append(f"- æƒ…æ„Ÿå…³é”®è¯: {', '.join(keywords)}")
            
            if emotion_data.get('error'):
                lines.append(f"\nâš ï¸ {emotion_data.get('error')}")
            
            lines.append("\nğŸ’¡ *é…ç½® InternLM API Key å¯è·å¾—ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’çš„æ·±åº¦åˆ†æ*")
        
        return "\n".join(lines)
    
    def generate_report(self, image_files: List) -> str:
        """
        ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        
        Args:
            image_files: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        if not image_files:
            return "âš ï¸ è¯·å…ˆä¸Šä¼ ç…§ç‰‡"
        
        report_lines = []
        report_lines.append("# ğŸ“· æ™ºèƒ½æ‘„å½±å­¦ä¹ åŠ©æ‰‹ - åˆ†ææŠ¥å‘Š")
        report_lines.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"\nåˆ†æç…§ç‰‡æ•°é‡: {len(image_files)}")
        report_lines.append("\n---\n")
        
        # åˆ†ææ¯å¼ ç…§ç‰‡
        for idx, image_file in enumerate(image_files, 1):
            image_path = image_file.name if hasattr(image_file, 'name') else str(image_file)
            
            report_lines.append(f"\n## ç…§ç‰‡ {idx}: {os.path.basename(image_path)}")
            report_lines.append("\n")
            
            try:
                # åˆ†æç…§ç‰‡
                result = self.analyze_single_photo(image_path)
                
                if result.get('status') == 'success':
                    # åŸºç¡€ä¿¡æ¯
                    if 'basic_info' in result:
                        report_lines.append(self.format_basic_info(result['basic_info']))
                        report_lines.append("\n")
                    
                    # è‰²å½©åˆ†æ
                    if 'color_analysis' in result:
                        report_lines.append(self.format_color_analysis(result['color_analysis']))
                        report_lines.append("\n")
                    
                    # æƒ…æ„Ÿåˆ†æ
                    if 'emotion_analysis' in result:
                        report_lines.append(self.format_emotion_analysis(result['emotion_analysis']))
                        report_lines.append("\n")
                else:
                    report_lines.append(f"âŒ åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
            except Exception as e:
                report_lines.append(f"âŒ å¤„ç†å‡ºé”™: {str(e)}")
            
            report_lines.append("\n---\n")
        
        # æ€»ç»“
        report_lines.append("\n## ğŸ“Š åˆ†ææ€»ç»“")
        report_lines.append(f"\næœ¬æ¬¡å…±åˆ†æäº† {len(image_files)} å¼ ç…§ç‰‡ã€‚")
        report_lines.append("\nå»ºè®®æ ¹æ®ä»¥ä¸Šåˆ†æç»“æœï¼Œé’ˆå¯¹æ€§åœ°æ”¹è¿›æ‘„å½±æŠ€å·§ã€‚")
        report_lines.append("\nğŸ’¡ æ›´å¤šæ‘„å½±çŸ¥è¯†ï¼Œè¯·å‚è€ƒ `photo-tutor/references/` ç›®å½•ä¸‹çš„èµ„æ–™ã€‚")
        
        return "\n".join(report_lines)


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    app = PhotoTutorApp()
    
    # ä½¿ç”¨ç®€å•çš„ Interface è€Œä¸æ˜¯ Blocks
    demo = gr.Interface(
        fn=app.generate_report,
        inputs=gr.File(
            label="ä¸Šä¼ ç…§ç‰‡ï¼ˆæ”¯æŒå¤šå¼ ï¼‰",
            file_count="multiple"
        ),
        outputs=gr.Markdown(label="åˆ†ææŠ¥å‘Š"),
        title="ğŸ“· æ™ºèƒ½æ‘„å½±å­¦ä¹ åŠ©æ‰‹",
        description="""
        ä¸Šä¼ ä½ çš„ç…§ç‰‡ï¼Œè·å¾—ä¸“ä¸šçš„æ‘„å½±åˆ†æå’Œå­¦ä¹ å»ºè®®ï¼
        
        **åŠŸèƒ½ç‰¹ç‚¹**ï¼š
        - ğŸ“¸ åŸºç¡€ä¿¡æ¯æå–ï¼ˆåˆ†è¾¨ç‡ã€EXIFã€æ›å…‰å‚æ•°ï¼‰
        - ğŸ¨ è‰²å½©ç¾å­¦åˆ†æï¼ˆå’Œè°åº¦ã€å¿ƒç†å­¦ã€è´¨é‡è¯„åˆ†ï¼‰
        - â¤ï¸ AI æƒ…æ„Ÿåˆ†æï¼ˆInternLM ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’ï¼‰
        
        **ä½¿ç”¨è¯´æ˜**ï¼š
        1. ä¸Šä¼ ä¸€å¼ æˆ–å¤šå¼ ç…§ç‰‡
        2. ç‚¹å‡»"Submit"æŒ‰é’®
        3. ç­‰å¾…åˆ†æå®Œæˆï¼ˆæ¯å¼ å›¾çº¦éœ€10-30ç§’ï¼‰
        4. æŸ¥çœ‹ç”Ÿæˆçš„è¯¦ç»†æŠ¥å‘Š
        """,
        article="""
        ### ğŸ’¡ æç¤º
        - æ”¯æŒ JPGã€PNG ç­‰å¸¸è§æ ¼å¼
        - å»ºè®®ä¸Šä¼ æ¸…æ™°ã€å®Œæ•´çš„ç…§ç‰‡
        - å·²é…ç½® InternLM APIï¼Œå¯è·å¾—ä¸“ä¸šåˆ†æ
        
        ### ğŸ”§ æŠ€æœ¯æ”¯æŒ
        - **åŸºç¡€åˆ†æ**: PILã€NumPyã€scikit-image
        - **AI åˆ†æ**: InternLM å¤šæ¨¡æ€æ¨¡å‹
        - **ç•Œé¢**: Gradio
        """,
        allow_flagging="never"
    )
    
    return demo


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
